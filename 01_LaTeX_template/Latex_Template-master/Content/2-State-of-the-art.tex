%% ==============================
\chapter{\iflanguage{ngerman}{Stand der Wissenschenschaft und Technik}{State of the art}}
\label{sec:state_of_the_art}
%% ==============================
This chapter describes the current state of the art of our work. We did a comprehensive literature research on the topic of object detection and pose estimation for robotics and different approaches to bridge the reality gab, which means the barrier to using simulated data on real robots. We describe the results of this literature research in the following sections. In Section 2.1, we reviews different methods which used on object detection and pose estimation for robotics. In Section 2.2, we focus on the approach domain randomization to bridge the reality gap. In Section 2.3, we give an overview of the domain adaptation which are used for training models to a previously unseen target domain.  Section 2.4 gives a summary to the these approaches.

\section{Object detection and pose estimation for robotics}
Object detection and pose estimation for robotics is a well-studied problem in the literature. Recent approaches typically involve offline construction or learning of a 3D model of objects in the scene (e.g., a full 3D mesh model \cite{tang2012textured} or a 3D metric feature representation \cite{collet2011moped}). At test time, features from the test data (e.g., Scale-Invariant Feature Transform [SIFT] features \cite{gordon2006and} or color co-occurrence histograms \cite{ekvall2005object} are matched with the 3D models (or features from the 3D models). For example, a black-box nonlinear optimization algorithm can be used to minimize the re-projection error of the SIFT points from the object model and the 2D points in the test image \cite{collet2009object}. Most successful approaches rely on using multiple camera frames \cite{collet2010efficient} or depth information \cite{tang2012textured}. There has also been some success with only monocular camera images \cite{collet2009object}.

These traditional approaches require less extensive training and take advantage of richer sensory data, allowing them to detect the full 3D pose of objects (position and orientation) without any assumptions about the location or size of the surface on which the objects are placed. However, in this thesis we aims to avoids the challenging problem of 3D reconstruction, and employs a simple, easy to implement deep learning-based pipeline that may scale better to more challenging problems.

\section{Domain Randomization}
Domain randomization is a complementary class of techniques for adaptation that is particularly well suited for simulation. With domain randomization, discrepancies between the source and target domains are modeled as variability in the source domain. Randomization in the visual domain has been used to directly transfer vision-based policies from simulation to the real world without requiring real images during training \cite{sadeghi2016cad2rl}, \cite{tobin2017domain}. 

Sadeghi and Levine \cite{sadeghi2016cad2rl} trained vision-based controllers for a quadrotor using only synthetically rendered scenes, and Tobin et al. \cite{tobin2017domain} demonstrated transferring image-based object detectors. Unlike previous methods, which sought to bridge the reality gap with high fidelity rendering \cite{james20163d}, their systems used only low fidelity rendering and modeled differences in visual appearance by randomizing scene properties such as lighting, textures, and camera placement. The approach in \cite{tobin2017domain} does not rely on precise camera information or calibration, instead randomizing the position, orientation, and field of view of the camera in the simulator. Whereas approach in \cite{sadeghi2016cad2rl} chooses textures from a dataset of around 200 pre-generated materials, most of which are realistic, the approach in \cite{tobin2017domain} use only non-realistic textures created by a simple random generation process. Figure 2.1 shows the rendering scene by Tobin et al. \cite{tobin2017domain} in their work.
\begin{figure}[h]
	\centering
	\includegraphics{Figures/Section2_Tobin}
	\caption{Rendered low-fidelity images with random camera positions, lighting conditions, and non-realistic textures in \cite{tobin2017domain} }
	\label{fig: tobin work}
\end{figure}

\section{Domain adaptation}
Another way to cross the reality gap is to learn from both simulation and real-world data. The computer vision community has devoted significant study to the problem of adapting vision-based models trained in a source domain to a previously unseen target domain (see, e.g., \cite{hoffman2014lsda}, \cite{hoffman2013efficient}, \cite{long2015learning}). A variety of approaches have been proposed, including re-training the model in the target domain (e.g., \cite{yosinski2014transferable}),  adapting the weights of the model based on the statistics of the source and target domains (e.g., \cite{li2016revisiting}), learning invariant features between domains (e.g., \cite{tzeng2014deep}), and learning a mapping from the target domain to the source domain (e.g., \cite{taigman2016unsupervised}). Researchers in the reinforcement learning community have also studied the problem of domain adaptation by learning invariant feature representations \cite{gupta2017learning}, adapting pretrained networks \cite{rusu2016progressive}, and other methods. See \cite{gupta2017learning} for a more complete treatment of domain adaptation in the reinforcement learning literature.

It is often faster to fine-tune a controller learned in simulation than to learn from scratch in the real world \cite{cutler2015efficient, kolter2007learning}. In \cite{ghadirzadeh2017deep}, the authors use a variational autoencoder trained on simulated data to encode trajectories of motor outputs corresponding to a desired behavior type (e.g., reaching, grasping) as a low-dimensional latent code. A policy is learned on real data mapping features to distributions over latent codes. The learned policy overcomes the reality gap by choosing latent codes that correspond to the desired physical behavior via exploration.

Domain adaptation has also been applied to robotic vision. Rusu et al. \cite{rusu2016sim} explore using the progressive network architecture to adapt a model that is pretrained on simulated pixels, and find it has better sample efficiency than fine-tuning or training in the real-world alone. In \cite{tzeng2015adapting}, the authors explore learning a correspondence between domains that allows the real images to be mapped into a space understood by the model. While both of the preceding approaches require reward functions or labeled data, which can be difficult to obtain in the real world, Mitash and collaborators \cite{mitash2017self} explore pretraining an object detector using realistic rendered images with randomized lighting from 3D models to bootstrap an automated learning process that does not require manually labeling data and uses only around 500 real-world samples.

\section{Overcoming the reality gap}
Previous work on leveraging simulated data for physical robotic experiments explored several strategies for bridging the reality gap. We summarize it as follows:

One type of approach is to make the simulator closely match the physical reality by performing system identification and using high-quality rendering. Though using realistic RGB rendering alone has had limited success for transferring to real robotic tasks \cite{james20163d}, incorporating realistic simulation of depth information can allow models trained on rendered images to transfer reasonably well to the real world \cite{planche2017depthsynth}. Combining data from high-quality simulators with other approaches like fine-tuning can also reduce the number of labeled samples required in the real world \cite{richter2016playing}. Unlike these approaches, the other type allows the use of low-quality renderers optimized for speed and not carefully matched to real-world textures, lighting, and scene configurations. And it requires no additional training on real-world data \cite{tobin2017domain}.

For a better result by overcoming the reality gap, the two types of approaches can be combined.





